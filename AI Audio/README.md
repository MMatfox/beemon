
# ğŸ Queen Presence Detection Using CNNs on Beehive Audio

This project focuses on detecting the presence of a queen bee in a hive using short audio recordings (3 seconds).  
The audio files are transformed into mel spectrograms, which are then classified by convolutional neural networks (CNNs).

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ sounds/
â”‚   â”œâ”€â”€ Queen_Spectrograms/          # Training images (queen present)
â”‚   â”œâ”€â”€ NonQueen_Spectrograms/       # Training images (no queen)
â”‚   â”œâ”€â”€ testQueen_spectrogram/       # Test images (queen)
â”‚   â””â”€â”€ testNonQueen_spectrogram/    # Test images (no queen)
â”œâ”€â”€ generate_spectrograms.py         # Script to convert .wav to .png spectrograms
â”œâ”€â”€ train_cnn.py                     # Train CNN from scratch
â”œâ”€â”€ train_finetune.py                # Fine-tune MobileNetV2
â”œâ”€â”€ evaluate_models.py               # Run prediction & evaluation on all models
â”œâ”€â”€ model_CNN.h5                     # CNN from scratch (trained model)
â”œâ”€â”€ model_CNN.tflite                 # CNN converted to TensorFlow Lite
â”œâ”€â”€ model_tuned.tflite               # Fine-tuned MobileNetV2 (TFLite)
â””â”€â”€ README.md
```

---

## ğŸ§  Model Architectures

| Model            | Description                                   |
|------------------|-----------------------------------------------|
| CNN from Scratch | Custom CNN trained only on spectrograms       |
| Fine-tuned CNN   | MobileNetV2 pre-trained on ImageNet and adapted |
| CNN (old)        | First version of custom CNN                   |

---

## ğŸ“Š Performance Summary

| Model           | Accuracy | Precision | Recall | F1-score |
|----------------|----------|-----------|--------|----------|
| **CNN (final)** | 0.675    | 0.818     | 0.466  | 0.594    |
| Fine-tuned CNN | 0.514    | 0.866     | 0.056  | 0.105    |
| CNN (old)      | 0.673    | 0.656     | 0.751  | 0.700    |

- The fine-tuned model failed to generalize, likely due to the domain gap between natural images (ImageNet) and spectrograms.
- The CNN from scratch outperformed all models, showing that training directly on spectrograms is more effective in this specific task.

---

## ğŸ¼ Spectrogram Generation

Raw `.wav` files were converted into 128Ã—128 mel spectrograms using librosa.  
Each spectrogram is saved as a `.png` image and used as CNN input.

```python
S = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=128)
S_dB = librosa.power_to_db(S, ref=np.max)
```

---

## âœ… Pros and Cons Comparison

### CNN from Scratch
- âœ… Tailored to your dataset  
- âœ… No pre-learned image bias  
- âœ… Better performance on spectrograms  
- âŒ Requires more training time  
- âŒ Needs large dataset  
- âŒ Risk of overfitting  

### Fine-tuned CNN (MobileNetV2)
- âœ… Faster training convergence  
- âœ… Works with small datasets  
- âœ… Easy to implement  
- âŒ Not optimized for spectrograms  
- âŒ Irrelevant features transferred  
- âŒ Fine-tuning can be tricky  

---

## ğŸ’» Requirements

- Python 3.9+
- TensorFlow 2.x
- Keras
- NumPy
- Librosa
- Matplotlib
- scikit-learn

```bash
pip install -r requirements.txt
```

---

## ğŸš€ How to Train

```bash
python train_cnn.py       # Train CNN from scratch
python train_finetune.py  # Fine-tune MobileNetV2
```

---

## ğŸ” How to Evaluate

```bash
python evaluate_models.py
```

All models are tested on separate test spectrogram folders.  
Metrics include accuracy, precision, recall and F1-score.

---

## ğŸ“¦ Deployment

The final CNN is exported in TensorFlow Lite format (`.tflite`) for use on edge devices.

